{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JDS Part 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKDp3LJrdWGqZKsxP9ooEe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw5QCsN1K277"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from torchsummary import summary"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlwHQc_GKS0I",
        "outputId": "99587765-85dd-487f-9a58-077b09b8baf7"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s985d-N6K2Dp"
      },
      "source": [
        "csvfile = '/content/drive/MyDrive/Projet-JDS/SMOTEd.csv'\r\n",
        "smoted = pd.read_csv(csvfile)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5ZX4gwxLm98"
      },
      "source": [
        "csv1 = '/content/drive/MyDrive/Projet-JDS/non_accident.csv'\r\n",
        "csv = pd.read_csv(csv1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7As4qhmJTJ2"
      },
      "source": [
        "# Transformation aux numéros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H2oO2SIZvRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3612953b-a8ed-4bf1-f207-d7d2a2de1d67"
      },
      "source": [
        "csv['WEATHER_CONDITION']= csv['WEATHER_CONDITION'].replace({'CLEAR':1,'RAIN':2,'CLOUDY/OVERCAST':3,'SNOW':4})\n",
        "csv['LIGHTING_CONDITION']= csv['LIGHTING_CONDITION'].replace({'DAYLIGHT':1,'DARKNESS, LIGHTED ROAD':2,'DARKNESS':3,'DUSK':4,'DAWN':5})\n",
        "csv['LIGHTING_CONDITION'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    370507\n",
              "2    212451\n",
              "3     81013\n",
              "4     62406\n",
              "5     57775\n",
              "Name: LIGHTING_CONDITION, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxoopZpLOxSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce522ce2-e498-4667-e4a4-e3ef312e6a25"
      },
      "source": [
        "csv['ROADWAY_SURFACE_COND']= csv['ROADWAY_SURFACE_COND'].replace({'DRY':1,'WET':2,'SNOW OR SLUSH':3})\n",
        "csv['ROADWAY_SURFACE_COND'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    509496\n",
              "2    140506\n",
              "3    134150\n",
              "Name: ROADWAY_SURFACE_COND, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-zOVmBKPxys"
      },
      "source": [
        "y = csv['accident'] #separating the target variable\r\n",
        "X = csv.drop(['accident',csv.columns[0]],axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaCRFkahPAdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4c77ac-b8a6-45c4-8c0d-38d19de24ef7"
      },
      "source": [
        "#%%time \r\n",
        "from imblearn.over_sampling import SMOTENC\r\n",
        "\r\n",
        "# By default, the values sampled are continous. We have to explicitely mention if we deal with categorical data\r\n",
        "sample = SMOTENC(random_state=2,categorical_features=[0,1,2,4,5,6,7],n_jobs=-1,sampling_strategy='minority')\r\n",
        "X_2, y_2 = sample.fit_resample(X, y.ravel())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4-axWhqPJMA"
      },
      "source": [
        "#from imblearn.under_sampling import ClusterCentroids\r\n",
        "#cc = ClusterCentroids(random_state=0)\r\n",
        "#X_resampled, y_resampled = cc.fit_resample(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbD7sclhPNrB"
      },
      "source": [
        "#y.value_counts()[0]/np.sum(y.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BRpGcVfRXPD",
        "outputId": "5aaed61c-2844-414a-e645-d340cb1ee522"
      },
      "source": [
        "print('The size of the generated dataset from Louis: {}' .format(len(y)))\r\n",
        "print('In that how much is accident: {}'.format(sum(y)))\r\n",
        "print('In that how much is non-accident: {}'.format(len(y) - sum(y)))\r\n",
        "print('The percentage of non-accident data: {}%'.format(y.value_counts()[0]/np.sum(y.value_counts())*100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the generated dataset from Louis: 784152\n",
            "In that how much is accident: 418560\n",
            "In that how much is non-accident: 365592\n",
            "The percentage of non-accident data: 46.62259357879594%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWqMpu1OBhQi",
        "outputId": "fc8c2c21-4a51-4c7e-ae42-67c01422adef"
      },
      "source": [
        "train_orig = pd.read_csv('/content/drive/MyDrive/Projet-JDS/train_orig.csv') #Original dataset"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2,3,4,7,8,10,11,12,13,14,15,17,18,24,25,26,27) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GCRi6DgB8GE",
        "outputId": "afae9098-6f05-4245-b539-e74b5452d898"
      },
      "source": [
        "train_orig['WEATHER_CONDITION'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLEAR              515099\n",
              "RAIN                59718\n",
              "SNOW                20040\n",
              "CLOUDY/OVERCAST     20027\n",
              "Name: WEATHER_CONDITION, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rUGlDtV3P6r"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfmvKwgCjRGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e06cb8-3480-4651-caf3-7534239b29a0"
      },
      "source": [
        "import torch\r\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\r\n",
        "from torch.utils.data.dataset import Dataset\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torchvision.utils import make_grid\r\n",
        "import torch.utils.data.sampler as sampler\r\n",
        "from torchsummary import summary\r\n",
        "from torch import nn, optim\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "print('Using device '+str(device))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GNhkqgbCotn"
      },
      "source": [
        "smoted = pd.read_csv('/content/drive/MyDrive/Projet-JDS/SMOTEd.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYhmXd1WehRO"
      },
      "source": [
        "y_2 = smoted['accident']\r\n",
        "X_2 = smoted.drop(['accident'],axis=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "v_uHPVDGjBD3",
        "outputId": "fb591ec0-afd1-42d0-ccf7-1bb7aa8331f0"
      },
      "source": [
        "X_2 #sanity check"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WEATHER_CONDITION</th>\n",
              "      <th>LIGHTING_CONDITION</th>\n",
              "      <th>CRASH_WEEKDAY</th>\n",
              "      <th>CRASH_HOUR</th>\n",
              "      <th>CRASH_Month</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>ROADWAY_SURFACE_COND</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>43.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>36.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837115</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>37.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837116</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>40.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837117</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>38.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837118</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>30.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837119</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>837120 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        WEATHER_CONDITION  LIGHTING_CONDITION  ...     y  ROADWAY_SURFACE_COND\n",
              "0                       1                   1  ...  43.0                     1\n",
              "1                       1                   1  ...  16.0                     1\n",
              "2                       1                   1  ...  35.0                     1\n",
              "3                       1                   2  ...  49.0                     1\n",
              "4                       3                   1  ...  47.0                     1\n",
              "...                   ...                 ...  ...   ...                   ...\n",
              "837115                  1                   2  ...  65.0                     1\n",
              "837116                  4                   1  ...  13.0                     3\n",
              "837117                  1                   2  ...  47.0                     3\n",
              "837118                  3                   3  ...  61.0                     1\n",
              "837119                  1                   2  ...  18.0                     3\n",
              "\n",
              "[837120 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeaQn2AnKNj1"
      },
      "source": [
        "# Preparing to split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CRpoKbmfGL-"
      },
      "source": [
        "idx= np.random.randint(0,len(smoted),size=len(smoted))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BOdGa0jxCRx"
      },
      "source": [
        "# 90% 5% 5%\n",
        "train_size = 0.9\n",
        "valid_size = 0.05\n",
        "test_size = 0.05"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOuTiTrf33bh"
      },
      "source": [
        "X_test,y_test = X_2.iloc[idx[0:int(test_size*len(idx))]], y_2.iloc[idx[0:int(test_size*len(idx))]]\r\n",
        "X_train,y_train = X_2.iloc[idx[int((test_size*len(idx))) : len(X_test) + int(train_size*len(idx))]], y_2.iloc[idx[int((test_size*len(idx))) : len(X_test) + int(train_size*len(idx))]]\r\n",
        "X_valid,y_valid = X_2.iloc[idx[ len(X_test) + int(train_size*len(idx)) :]], y_2.iloc[idx[ len(X_test) + int(train_size*len(idx)) :]]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNHizNWOc6KO",
        "outputId": "a1808f8f-51a5-4d91-a24c-54b9c2cc3112"
      },
      "source": [
        "y_valid"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "656331    0\n",
              "549984    0\n",
              "825164    0\n",
              "111152    1\n",
              "34834     1\n",
              "         ..\n",
              "172789    1\n",
              "64193     1\n",
              "765178    0\n",
              "669738    0\n",
              "529410    0\n",
              "Name: accident, Length: 41856, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIWxm6mEFllP"
      },
      "source": [
        "\r\n",
        "tensor_xtrain = torch.Tensor(X_train.values) # transformation to torch tensor\r\n",
        "tensor_ytrain = torch.Tensor(y_train.values)\r\n",
        "\r\n",
        "traingrouping = TensorDataset(tensor_xtrain,tensor_ytrain) # creating datset\r\n",
        "train_loader = DataLoader(traingrouping,batch_size=128) # creating dataloader"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxE5GKJAITSx"
      },
      "source": [
        "tensor_xvalid = torch.Tensor(X_valid.values) # transformation to torch tensor\r\n",
        "tensor_yvalid = torch.Tensor(y_valid.values)\r\n",
        "\r\n",
        "validgrouping = TensorDataset(tensor_xvalid,tensor_yvalid) # creating datset\r\n",
        "valid_loader = DataLoader(validgrouping,batch_size=128) # creating dataloader"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHwCWqdgMIDv"
      },
      "source": [
        "tensor_xtest = torch.Tensor(X_test.values) # transform to torch tensor\r\n",
        "tensor_ytest = torch.Tensor(y_test.values)\r\n",
        "\r\n",
        "testgrouping = TensorDataset(tensor_xtest,tensor_ytest) # creating datset\r\n",
        "test_loader = DataLoader(testgrouping,batch_size=128) # creating dataloader"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWYWlFrKBKC1"
      },
      "source": [
        "class neuralnetwork(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "        super(neuralnetwork, self).__init__()\r\n",
        "        self.fc1 = nn.Linear(8,100)\r\n",
        "        self.fc2 = nn.Linear(100,256)\r\n",
        "        self.fc3 = nn.Linear(256,256)\r\n",
        "        self.fc4 = nn.Linear(256,2)\r\n",
        "      #  self.dropout = nn.Dropout(p=0.15)\r\n",
        "  def forward(self,x):\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = (F.relu(self.fc2(x)))\r\n",
        "        x = F.relu(self.fc3(x))\r\n",
        "        x = self.fc4(x)\r\n",
        "        return x"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0v1h3ehCfYk",
        "outputId": "5755e932-1436-439c-b143-09382fc3eb45"
      },
      "source": [
        "model = neuralnetwork()\r\n",
        "model.to(device=device)\r\n",
        "summary(model,(1,8))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 100]             900\n",
            "            Linear-2               [-1, 1, 256]          25,856\n",
            "            Linear-3               [-1, 1, 256]          65,792\n",
            "            Linear-4                 [-1, 1, 2]             514\n",
            "================================================================\n",
            "Total params: 93,062\n",
            "Trainable params: 93,062\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.36\n",
            "Estimated Total Size (MB): 0.36\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSZa22quEO8X"
      },
      "source": [
        "#optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGtssV7LD2Tq"
      },
      "source": [
        "#optimizer = optim.Adam(model.parameters(),lr=0.01)\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001,momentum=0.9)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhBu1MKkEcWz"
      },
      "source": [
        "# Criterion: Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB1UNMqSEbW-"
      },
      "source": [
        "lossfunction = nn.CrossEntropyLoss()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7YySXs1Ejjz"
      },
      "source": [
        "def training(n_epochs, train_loader, valid_loader, model, criterion, optimizer):\r\n",
        "\r\n",
        "  train_losses, valid_losses = [], []\r\n",
        "\r\n",
        "  valid_loss_min = np.Inf\r\n",
        "\r\n",
        "  for epoch in range(n_epochs):\r\n",
        "      train_loss, valid_loss = 0, 0\r\n",
        "\r\n",
        "      model.train()\r\n",
        "      for data, label in train_loader:\r\n",
        "          data = data.to(device=device, dtype=torch.float32)\r\n",
        "          label = label.to(device=device, dtype=torch.long)\r\n",
        "          optimizer.zero_grad()\r\n",
        "          output = model(data)\r\n",
        "          loss = criterion(output, label)\r\n",
        "          loss.backward()\r\n",
        "          optimizer.step()\r\n",
        "          train_loss += loss.item() * data.size(0)\r\n",
        "      \r\n",
        "      model.eval()\r\n",
        "      for data, label in valid_loader:\r\n",
        "          data = data.to(device=device, dtype=torch.float32)\r\n",
        "          label = label.to(device=device, dtype=torch.long)\r\n",
        "          with torch.no_grad():\r\n",
        "              output = model(data)\r\n",
        "          loss = criterion(output,label)\r\n",
        "          valid_loss += loss.item() * data.size(0)\r\n",
        "  \r\n",
        "      train_loss /= len(train_loader.sampler)\r\n",
        "      valid_loss /= len(valid_loader.sampler)\r\n",
        "      train_losses.append(train_loss)\r\n",
        "      valid_losses.append(valid_loss)\r\n",
        "      \r\n",
        "      print('epoch: {} \\ttraining Loss: {:.6f} \\tvalidation Loss: {:.6f}'.format(epoch+1, train_loss, valid_loss))\r\n",
        "\r\n",
        "      # save model if validation loss has decreased\r\n",
        "      if valid_loss <= valid_loss_min:\r\n",
        "          print('validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\r\n",
        "          valid_loss_min,\r\n",
        "          valid_loss))\r\n",
        "          torch.save(model.state_dict(), 'model.pt')\r\n",
        "          valid_loss_min = valid_loss\r\n",
        "      \r\n",
        "  return train_losses, valid_losses"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYMpY-g5E76A",
        "outputId": "eb230e15-5908-4d53-e3aa-5d1cf109c3db"
      },
      "source": [
        "\r\n",
        "train_losses, valid_losses = training(50, train_loader, valid_loader, model, lossfunction, optimizer)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 \ttraining Loss: 0.607420 \tvalidation Loss: 0.577233\n",
            "validation loss decreased (inf --> 0.577233).  Saving model ...\n",
            "epoch: 2 \ttraining Loss: 0.526167 \tvalidation Loss: 0.485656\n",
            "validation loss decreased (0.577233 --> 0.485656).  Saving model ...\n",
            "epoch: 3 \ttraining Loss: 0.473376 \tvalidation Loss: 0.459419\n",
            "validation loss decreased (0.485656 --> 0.459419).  Saving model ...\n",
            "epoch: 4 \ttraining Loss: 0.446854 \tvalidation Loss: 0.447489\n",
            "validation loss decreased (0.459419 --> 0.447489).  Saving model ...\n",
            "epoch: 5 \ttraining Loss: 0.430767 \tvalidation Loss: 0.446710\n",
            "validation loss decreased (0.447489 --> 0.446710).  Saving model ...\n",
            "epoch: 6 \ttraining Loss: 0.418884 \tvalidation Loss: 0.429499\n",
            "validation loss decreased (0.446710 --> 0.429499).  Saving model ...\n",
            "epoch: 7 \ttraining Loss: 0.408381 \tvalidation Loss: 0.411018\n",
            "validation loss decreased (0.429499 --> 0.411018).  Saving model ...\n",
            "epoch: 8 \ttraining Loss: 0.399193 \tvalidation Loss: 0.411198\n",
            "epoch: 9 \ttraining Loss: 0.390666 \tvalidation Loss: 0.386955\n",
            "validation loss decreased (0.411018 --> 0.386955).  Saving model ...\n",
            "epoch: 10 \ttraining Loss: 0.384398 \tvalidation Loss: 0.380394\n",
            "validation loss decreased (0.386955 --> 0.380394).  Saving model ...\n",
            "epoch: 11 \ttraining Loss: 0.379147 \tvalidation Loss: 0.374469\n",
            "validation loss decreased (0.380394 --> 0.374469).  Saving model ...\n",
            "epoch: 12 \ttraining Loss: 0.375168 \tvalidation Loss: 0.374521\n",
            "epoch: 13 \ttraining Loss: 0.371399 \tvalidation Loss: 0.368575\n",
            "validation loss decreased (0.374469 --> 0.368575).  Saving model ...\n",
            "epoch: 14 \ttraining Loss: 0.368344 \tvalidation Loss: 0.373030\n",
            "epoch: 15 \ttraining Loss: 0.365987 \tvalidation Loss: 0.365600\n",
            "validation loss decreased (0.368575 --> 0.365600).  Saving model ...\n",
            "epoch: 16 \ttraining Loss: 0.363489 \tvalidation Loss: 0.364792\n",
            "validation loss decreased (0.365600 --> 0.364792).  Saving model ...\n",
            "epoch: 17 \ttraining Loss: 0.361504 \tvalidation Loss: 0.364284\n",
            "validation loss decreased (0.364792 --> 0.364284).  Saving model ...\n",
            "epoch: 18 \ttraining Loss: 0.359736 \tvalidation Loss: 0.361253\n",
            "validation loss decreased (0.364284 --> 0.361253).  Saving model ...\n",
            "epoch: 19 \ttraining Loss: 0.358151 \tvalidation Loss: 0.359038\n",
            "validation loss decreased (0.361253 --> 0.359038).  Saving model ...\n",
            "epoch: 20 \ttraining Loss: 0.356375 \tvalidation Loss: 0.356418\n",
            "validation loss decreased (0.359038 --> 0.356418).  Saving model ...\n",
            "epoch: 21 \ttraining Loss: 0.355158 \tvalidation Loss: 0.356802\n",
            "epoch: 22 \ttraining Loss: 0.353747 \tvalidation Loss: 0.353374\n",
            "validation loss decreased (0.356418 --> 0.353374).  Saving model ...\n",
            "epoch: 23 \ttraining Loss: 0.352335 \tvalidation Loss: 0.357876\n",
            "epoch: 24 \ttraining Loss: 0.351148 \tvalidation Loss: 0.353585\n",
            "epoch: 25 \ttraining Loss: 0.350188 \tvalidation Loss: 0.357819\n",
            "epoch: 26 \ttraining Loss: 0.349483 \tvalidation Loss: 0.353058\n",
            "validation loss decreased (0.353374 --> 0.353058).  Saving model ...\n",
            "epoch: 27 \ttraining Loss: 0.348249 \tvalidation Loss: 0.352011\n",
            "validation loss decreased (0.353058 --> 0.352011).  Saving model ...\n",
            "epoch: 28 \ttraining Loss: 0.347355 \tvalidation Loss: 0.354797\n",
            "epoch: 29 \ttraining Loss: 0.346483 \tvalidation Loss: 0.354329\n",
            "epoch: 30 \ttraining Loss: 0.345731 \tvalidation Loss: 0.351987\n",
            "validation loss decreased (0.352011 --> 0.351987).  Saving model ...\n",
            "epoch: 31 \ttraining Loss: 0.345029 \tvalidation Loss: 0.352540\n",
            "epoch: 32 \ttraining Loss: 0.344298 \tvalidation Loss: 0.350068\n",
            "validation loss decreased (0.351987 --> 0.350068).  Saving model ...\n",
            "epoch: 33 \ttraining Loss: 0.343458 \tvalidation Loss: 0.346907\n",
            "validation loss decreased (0.350068 --> 0.346907).  Saving model ...\n",
            "epoch: 34 \ttraining Loss: 0.342777 \tvalidation Loss: 0.346543\n",
            "validation loss decreased (0.346907 --> 0.346543).  Saving model ...\n",
            "epoch: 35 \ttraining Loss: 0.341939 \tvalidation Loss: 0.348170\n",
            "epoch: 36 \ttraining Loss: 0.341315 \tvalidation Loss: 0.344964\n",
            "validation loss decreased (0.346543 --> 0.344964).  Saving model ...\n",
            "epoch: 37 \ttraining Loss: 0.340732 \tvalidation Loss: 0.350693\n",
            "epoch: 38 \ttraining Loss: 0.340208 \tvalidation Loss: 0.344962\n",
            "validation loss decreased (0.344964 --> 0.344962).  Saving model ...\n",
            "epoch: 39 \ttraining Loss: 0.339528 \tvalidation Loss: 0.345021\n",
            "epoch: 40 \ttraining Loss: 0.338792 \tvalidation Loss: 0.342839\n",
            "validation loss decreased (0.344962 --> 0.342839).  Saving model ...\n",
            "epoch: 41 \ttraining Loss: 0.338398 \tvalidation Loss: 0.343328\n",
            "epoch: 42 \ttraining Loss: 0.337685 \tvalidation Loss: 0.342842\n",
            "epoch: 43 \ttraining Loss: 0.336975 \tvalidation Loss: 0.340854\n",
            "validation loss decreased (0.342839 --> 0.340854).  Saving model ...\n",
            "epoch: 44 \ttraining Loss: 0.336721 \tvalidation Loss: 0.341864\n",
            "epoch: 45 \ttraining Loss: 0.336243 \tvalidation Loss: 0.339899\n",
            "validation loss decreased (0.340854 --> 0.339899).  Saving model ...\n",
            "epoch: 46 \ttraining Loss: 0.335655 \tvalidation Loss: 0.340120\n",
            "epoch: 47 \ttraining Loss: 0.335182 \tvalidation Loss: 0.341122\n",
            "epoch: 48 \ttraining Loss: 0.334574 \tvalidation Loss: 0.339505\n",
            "validation loss decreased (0.339899 --> 0.339505).  Saving model ...\n",
            "epoch: 49 \ttraining Loss: 0.334240 \tvalidation Loss: 0.339025\n",
            "validation loss decreased (0.339505 --> 0.339025).  Saving model ...\n",
            "epoch: 50 \ttraining Loss: 0.333702 \tvalidation Loss: 0.341421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSyZoi-qFAFJ"
      },
      "source": [
        "\r\n",
        "\r\n",
        "def evaluation(model, test_loader, criterion, detail): \r\n",
        "\r\n",
        "  test_loss = 0.0\r\n",
        "  class_correct = list(0. for i in range(2))\r\n",
        "  class_total = list(0. for i in range(2))\r\n",
        "  class_names = ['class {}'.format(i) for i in range(2)]\r\n",
        "  print(class_names)\r\n",
        "  model.eval()\r\n",
        "  for data, label in test_loader:\r\n",
        "\r\n",
        "      data = data.to(device=device, dtype=torch.float32)\r\n",
        "      label = label.to(device=device, dtype=torch.long)\r\n",
        "\r\n",
        "      with torch.no_grad():\r\n",
        "          output = model(data)\r\n",
        "      loss = criterion(output, label)\r\n",
        "      test_loss += loss.item()*data.size(0)\r\n",
        "      _, pred = torch.max(output, 1)\r\n",
        "      correct = np.squeeze(pred.eq(label.data.view_as(pred)))\r\n",
        "\r\n",
        "      for i in range(len(label)):\r\n",
        "          digit = label.data[i]\r\n",
        "          class_correct[digit] += correct[i].item()\r\n",
        "          class_total[digit] += 1\r\n",
        "\r\n",
        "  test_loss = test_loss/len(test_loader.sampler)\r\n",
        "  print('test Loss: {:.6f}\\n'.format(test_loss))\r\n",
        "  if detail :\r\n",
        "    for i in range(2):\r\n",
        "      if class_total[i] != 0:\r\n",
        "        print('test accuracy of %s: %2d%% (%2d/%2d)' % (class_names[i], 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\r\n",
        "      #else:\r\n",
        "        #print('test accuracy of {}: 0/0 (no sample in this class)'.format(i))\r\n",
        "\r\n",
        "  print('\\n test accuracy (overall): %2.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lhHlWvnJeOi",
        "outputId": "368c0f8d-f7bc-4926-ac89-86567ec55e76"
      },
      "source": [
        "evaluation(model,test_loader,lossfunction,True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['class 0', 'class 1']\n",
            "test Loss: 0.334596\n",
            "\n",
            "test accuracy of class 0: 81% (17063/20892)\n",
            "test accuracy of class 1: 88% (18642/20964)\n",
            "\n",
            " test accuracy (overall): 85.30% (35705/41856)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkPzNMwnLjkQ",
        "outputId": "07c840f8-834a-46c0-f184-a998e9db16f9"
      },
      "source": [
        "evaluation(model,valid_loader,lossfunction,True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['class 0', 'class 1']\n",
            "test Loss: 0.341421\n",
            "\n",
            "test accuracy of class 0: 81% (17082/20980)\n",
            "test accuracy of class 1: 88% (18445/20876)\n",
            "\n",
            " test accuracy (overall): 84.88% (35527/41856)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C9_Iq3i92N2"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYGWiCyfV4YS"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS_VsSZS-nHU"
      },
      "source": [
        "\r\n",
        "rf = RandomForestClassifier()\r\n",
        "modelRF = rf.fit(X_train.values,y_train.values)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIwLlVloUvhZ",
        "outputId": "6b1617ef-268d-496f-a1d5-9d8348715db2"
      },
      "source": [
        "testpredicted = rf.predict(X_test)\r\n",
        "\r\n",
        "print( ( len(testpredicted[y_test==0]) - np.sum(testpredicted[y_test==0]) ) / len(testpredicted[y_test==0]) )\r\n",
        "print( np.sum(testpredicted[y_test==1]) / len(testpredicted[y_test==1]) )"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.933850277618227\n",
            "0.9559244419004007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTQCzMXnZBXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e656ef-923b-4c87-9abb-ce4bce24933d"
      },
      "source": [
        "validpredicted = modelRF.predict(X_valid)\r\n",
        "\r\n",
        "print( ( len(testpredicted[y_test==0]) - np.sum(testpredicted[y_test==0]) ) / len(testpredicted[y_test==0]) )\r\n",
        "print( np.sum(testpredicted[y_test==1]) / len(testpredicted[y_test==1]) )"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.933850277618227\n",
            "0.9559244419004007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8SYwhOjZAZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dce52ab-a5fc-4138-8531-6fd301b48522"
      },
      "source": [
        "np.sum(testpredicted==y_test)/len(y_test)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9449063455657493"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4WTtZe-Bk12",
        "outputId": "6ae10a50-41c8-4e0c-b666-07efcf0ca9dc"
      },
      "source": [
        "np.sum(validpredicted==y_valid)/len(y_valid)\r\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9449780198776758"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhS3IamaGjmQ",
        "outputId": "90c74220-423e-4774-ab78-e5caa3f85c4b"
      },
      "source": [
        "validpredicted = modelRF.predict(X_valid.values)\r\n",
        "print( ( len(validpredicted[y_valid==0]) - np.sum(validpredicted[y_valid==0]) ) / len(validpredicted[y_valid==0]) )\r\n",
        "print( np.sum(validpredicted[y_valid==1]) / len(validpredicted[y_valid==1]) )"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9367016205910391\n",
            "0.9532956505077601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ThWWvZtKdes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90689a4-ae72-423f-87f4-ab4f34208804"
      },
      "source": [
        "modelRF.predict_proba([[ 2.,  1.,  5., 15.,  5., 20., 7.,  2.]])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.53, 0.47]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tUKV49eKiaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8119d45d-44f7-4d66-efe5-986270430214"
      },
      "source": [
        "X_test.values[-2]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.,  5.,  3., 17.,  8., 20., 56.,  1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8whUIgLKmpgC"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7Vw505kKo5X"
      },
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi4919nzmwHa",
        "outputId": "53976df7-2f8d-4a84-fbcc-217ee5d9c94e"
      },
      "source": [
        "modelsvm = LinearSVC(max_iter =5000)\r\n",
        "modelsvm.fit(X_train.values, y_train.values)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=5000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzK301cupGrE"
      },
      "source": [
        "predictedsvmtest = modelsvm.predict(X_test.values)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip_c9fz5p2f0",
        "outputId": "6409efe4-9865-4a2d-d8fd-c55f7988ac46"
      },
      "source": [
        "np.sum( (predictedsvmtest==y_test).values )/len(y_test)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6293482415902141"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ytg0x0Xnpbn"
      },
      "source": [
        "#Validation set testing - Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2hhP2f_p_yE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f6531d-6274-4b15-a0e7-12d2f9b455ef"
      },
      "source": [
        "predictedsvmvalid = modelsvm.predict(X_valid.values)\r\n",
        "np.sum( (predictedsvmvalid==y_valid).values )/len(y_valid)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.627723623853211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBrMDZezgKqf",
        "outputId": "f7979d3f-8af5-4003-e3f6-b3b71853e309"
      },
      "source": [
        "predictedsvmtrain = modelsvm.predict(X_train.values)\r\n",
        "np.sum( (predictedsvmtrain==y_train).values )/len(y_train)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6282001252973156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv1jUi3MpAru"
      },
      "source": [],
      "execution_count": 64,
      "outputs": []
    }
  ]
}